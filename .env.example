# ------------------------------------------------------------------------------
# Next.js React Notion X Environment Variables
#
# This file contains all the environment variables needed to run the application.
# Copy this file to .env.local and fill in the values.
#
# - Required variables must be set for the application to run.
# - Optional variables can be left blank if you don't need the feature.
# ------------------------------------------------------------------------------

# -- Required ------------------------------------------------------------------

# Notion
# Find your Notion root page ID by opening the page in your browser and
# copying the ID from the URL. It's the 32-character string at the end.
# e.g. https://www.notion.so/your-workspace/My-Page-0123456789abcdef0123456789abcdef
NOTION_ROOT_PAGE_ID=

# -- AI / RAG / Chat Features --------------------------------------------------
# These are required for the AI chat functionality.

# OpenAI API Key
# Get yours from https://platform.openai.com/api-keys
OPENAI_API_KEY=

# Google Gemini (optional)
# Obtain a key from https://aistudio.google.com/app/apikey
# GOOGLE_API_KEY=

# Model selection (provider + model combined)
# LLM_MODEL="OpenAI gpt-4o-mini"
# EMBEDDING_MODEL="OpenAI text-embedding-3-small (v1)"
# EMBEDDING_SPACE_ID=openai_te3s_v1  # optional, inferred from EMBEDDING_MODEL when omitted

# Supabase credentials for vector storage (RAG)
# Get these from your Supabase project settings.
SUPABASE_URL=https://<your-supabase-project>.supabase.co
SUPABASE_ANON_KEY=
SUPABASE_SERVICE_ROLE_KEY=

# -- Optional ------------------------------------------------------------------

# Admin Dashboard Basic Auth
# Protects the /admin routes with a username and password.
ADMIN_DASH_USER=
ADMIN_DASH_PASS=

# AI / RAG / Chat Configuration (has defaults)
# You can override the default models and parameters for the AI chat.
# DEFAULT_ENGINE=lc    # or 'native'. 'lc' for LangChain, 'native' for direct OpenAI API.
# LLM_MODEL="OpenAI gpt-4o-mini"
# EMBEDDING_MODEL="OpenAI text-embedding-3-small (v1)"
# EMBEDDING_SPACE_ID=openai_te3s_v1
# LLM_TEMPERATURE=0.0
# RAG_TOP_K=5
# RAG_SIMILARITY_THRESHOLD=0.78
# CHAT_CONTEXT_TOKEN_BUDGET=1200
# CHAT_CONTEXT_CLIP_TOKENS=320
# CHAT_HISTORY_TOKEN_BUDGET=900
# CHAT_SUMMARY_ENABLED=true
# CHAT_SUMMARY_TRIGGER_TOKENS=400
# CHAT_SUMMARY_MAX_TURNS=6
# CHAT_SUMMARY_MAX_CHARS=600
# CHAT_CHITCHAT_KEYWORDS="hello,hi,how are you,whats up,what is up,tell me a joke"
# CHAT_FALLBACK_CHITCHAT_CONTEXT="This is a light-weight chit-chat turn. Keep the response concise, warm, and avoid citing the knowledge base."
# CHAT_FALLBACK_COMMAND_CONTEXT="The user is asking for an action/command. You must politely decline to execute actions and instead explain what is possible."

# Ollama (local LLM) configuration
# OLLAMA_BASE_URL=http://localhost:11434
# OLLAMA_MODEL_DEFAULT=mistral
# OLLAMA_ENABLE_IN_PROD=false
# OLLAMA_TIMEOUT_MS=30000
# OLLAMA_MAX_TOKENS=1024

# Analytics
# NEXT_PUBLIC_FATHOM_ID=
# NEXT_PUBLIC_POSTHOG_ID=

# Twitter/X Integration
# For rendering tweets more efficiently.
# TWITTER_ACCESS_TOKEN=

# Redis for Preview Image Caching
# See site.config.ts to enable (isRedisEnabled).
# REDIS_HOST=
# REDIS_PASSWORD=
# REDIS_USER='default'
# REDIS_NAMESPACE='preview-images'

# Notion API Overrides (for advanced use cases like self-hosted Notion)
# NOTION_API_BASE_URL=
# NOTION_PAGE_CACHE_TTL=60 # Overrides default cache TTL in seconds.
